[
  {
    "objectID": "reports/income-prediction.html",
    "href": "reports/income-prediction.html",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "",
    "text": "Here, we tried to find the classification models with the highest accuracy on predicting if an individual’s income is greater than 50K/yr based on census data. Our final classifier has a reasonable performance on the unseen test data. We observed the Logistic Regression validation accuracy of 0.849 and the RBF-SVM test accuracy of 0.855.\nThe prediction model can possibly be further improved by pruning more features that are irrelevant to the prediction, since we are using almost all of the features for fitting the classifiers."
  },
  {
    "objectID": "reports/income-prediction.html#summary",
    "href": "reports/income-prediction.html#summary",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "",
    "text": "Here, we tried to find the classification models with the highest accuracy on predicting if an individual’s income is greater than 50K/yr based on census data. Our final classifier has a reasonable performance on the unseen test data. We observed the Logistic Regression validation accuracy of 0.849 and the RBF-SVM test accuracy of 0.855.\nThe prediction model can possibly be further improved by pruning more features that are irrelevant to the prediction, since we are using almost all of the features for fitting the classifiers."
  },
  {
    "objectID": "reports/income-prediction.html#introduction",
    "href": "reports/income-prediction.html#introduction",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "Introduction",
    "text": "Introduction\nA lot of factors impact an individual’s income. We see how wealth remains concentrated as the top 1% held 35% of the total wealth in 2022 (Kuhn and Rı́os-Rull (2025)). More recently, from 2024 to 2025, the U.S. Federal Reserve shows 35% of the family income less than 50K per year (Federal Reserve System (2025)). It is a big topic because it involves each family’s economic well-being.\nThis notebook explores the Adult Income dataset to understand how different demographic and employment characteristics relate to whether a person earns more or less than $50,000 per year. The analysis begins with exploring patterns in the data, identifying any issues, and preparing the dataset for modeling. After cleaning and preprocessing, we build and evaluate predictive models to see how well income levels can be predicted using the available features."
  },
  {
    "objectID": "reports/income-prediction.html#methods",
    "href": "reports/income-prediction.html#methods",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "Methods",
    "text": "Methods\n\nData\nThe data set used here is from UC Irvine Machine Learning Repository, extracted by Barry Becker from the 1994 Census database (Becker and Kohavi (1996)).\n\n\nAnalysis\nThe algorithms below are considered for predicting whether if an individual’s income was above 50K/year or not: decision tree, k-nearest neighbors (k-nn), support vector machine with RBF kernel (SVM-RBF), logistic regression, gaussian naive bayes. All variables were used to fit the model, with the exception of: - fnlwgt: useless, since each row has a unique value - education-num: due to redundancy with education - race: for ethical reasons.\nData was split with 80% into the test set, and 20% into the train set to increase training time due to the vast amount of data. Imputation, one-hot encoding, and ordinal encoding are all done accordingly with details explained below. For model selection, we first conduct 5-fold cross-validation on all the models with default hyperparameters. Then, we select the top two models (Logistic Regression and SVM-RBF) to conduct a random search of hyperparameters with 5-fold cross-validation using accuracy as the classification metric. Finally, we used the best estimators of each to determine their accuracies on unseen test data.\n\n\nEDA\nLet us first try to look at the number of data points we have for each class.\n\n\n\n\n\n\nFigure 1: Income class distribution. Counts for &lt;=50K vs &gt;50K show the class mix before modeling.\n\n\n\nHere in Figure 1, we clearly see there is class imbalance in the data, with more individuals earning &lt;=50K than &gt;50K. This means that a naive classifier that always predicts the majority class would already achieve non-trivial accuracy. Therefore, we must compare our models not just to a 50–50 baseline but also to this majority-class baseline. In future work, we could explore class-weighted loss functions or threshold tuning to better capture the minority high-income group.\n\nCorrelations and Redundancy\n\n\n\n\n\n\nFigure 2: Features Correlations Heatmap.\n\n\n\nIn Figure 2, we see that there are no extremely strong correlations between any pair of features, suggesting that severe multicollinearity is unlikely. Some moderate associations exist (e.g., between age and education, or hours worked and income-related variables), but they are not high enough to destabilize models like Logistic Regression. This supports our decision to keep most features, while still considering more advanced dimensionality reduction or feature selection later.\nTaken together, these first checks show a moderate class imbalance and largely mild correlations, so we plan to watch class weighting while keeping most features intact for modeling.\n\n\nKey Distributions\n\n\n\n\n\n\nFigure 3: Age distribution (smoothed density). The density view confirms the central mass in mid-career ages.\n\n\n\nFigure Figure 3 shows a skew toward mid-career ages, suggesting that experience- and tenure-related features may be informative. We also expect interactions with hours worked and education, since older individuals with higher education might have different income trajectories than younger individuals working similar hours.\nThe bulk of observations sit in the prime working ages, so discriminating power may come more from labor variables (hours, occupation) and capital gains than from age alone.\n\n\n\n\n\n\nFigure 4: Education levels. Higher counts appear in high-school/some-college bins; advanced degrees are rarer.\n\n\n\nFigure 4 highlights that most of the population clusters around mid-tier education levels such as high school and some college. Advanced degrees (e.g., Masters, Doctorate) are relatively rare, which means that their corresponding one-hot encoded levels have few observations. Regularization or grouping of similar education categories can prevent the model from overreacting to these small bins while still capturing the broad effect of education on income. grouping can prevent the model from overreacting to those small bins while still capturing the broad education effect.\n\n\n\n\n\n\nFigure 5: Race distribution. Most records fall in the majority category, with smaller minority groups.\n\n\n\nFigure 5 shows class imbalance across race groups, which reinforces the need for careful interpretation of fairness and representation. Even though we chose to exclude race from our predictive models for ethical reasons, this imbalance is important context for understanding the demographic makeup of the dataset and the societal factors behind income disparities.\nThis imbalance means any downstream interpretation should consider fairness; we may explore reweighting or sensitivity checks in future work to ensure predictions are not driven by majority representation alone.\n\n\n\n\n\n\nFigure 6: Marital status distribution. Married categories dominate, followed by never-married.\n\n\n\nFigure 6 suggests marital status may proxy for household stability or earning patterns; for instance, married individuals might have different labor participation or income levels than those who are never married. We expect interactions with occupation, hours worked, and possibly age.\nMarital status can also interact with dependents and life stage; inspecting combined effects will show whether it truly adds signal or just tracks broader demographic patterns.\n\n\n\n\n\n\nFigure 7: Native country counts. The vast majority are from the United States; other countries are sparse.\n\n\n\nFigure 7 shows heavy sparsity outside the United States, so grouping rare countries into broader regions (e.g., “Other”) could stabilize estimates and reduce noise in the model. Without grouping, many country-level dummy variables would be based on very few observations.\nOverall, the categorical sparsity (education extremes, non-U.S. countries) and demographic skews (race, marital status) argue for careful encoding and potential grouping, while the moderate class imbalance suggests testing class weights during model training.\n\n\n\nModel comparison and interpretation\nFrom Table 1, we can see that RBF-SVM is slightly more accurate than the other models. Logistic Regression is close in accuracy, and its interpretability is better due to its use of linear coefficients that can be mapped to odds ratios. Decision trees and k-NN trail behind in accuracy under the chosen preprocessing and hyperparameter defaults, and Gaussian Naive Bayes performs the worst, likely because its independence assumptions do not hold well for this dataset.\n\n\n\n\nTable 1: Cross validation summary for different models.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel\ntrain_accuracy_mean\ntrain_accuracy_std\ntest_accuracy_mean\ntest_accuracy_std\nfit_time_mean\nscore_time_mean\n\n\n\n\nSVM-RBF\n0.866247\n0.00147473\n0.855037\n0.00667547\n0.586047\n0.309393\n\n\nLogisticRegression\n0.851454\n0.00191879\n0.849304\n0.0078078\n0.0400904\n0.00131488\n\n\nKNN\n0.88232\n0.00180596\n0.834049\n0.00638451\n0.00424371\n0.0638126\n\n\nDecisionTree\n0.985437\n0.000514588\n0.814189\n0.0045412\n0.0195274\n0.00144496\n\n\nDummy-most_frequent\n0.760749\n5.3867e-05\n0.760749\n0.000215433\n0.00200963\n0.000862169\n\n\nGaussianNB\n0.309787\n0.00417648\n0.308148\n0.0104979\n0.00577421\n0.00150285\n\n\n\n\n\n\n\n\nThere is also a computational trade-off: SVM-RBF is more expensive to train and tune than Logistic Regression, especially on large datasets with many one-hot encoded features. Thus, the choice between these models depends not only on accuracy but also on interpretability and computational constraints. In many applied settings, Logistic Regression may be a more practical default."
  },
  {
    "objectID": "reports/income-prediction.html#results-and-discussion",
    "href": "reports/income-prediction.html#results-and-discussion",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nFrom the analyses above, we discovered that Logistic Regression and SVM-RBF are the best classification models for predicting income among the algorithms we tried. The Logistic Regression model achieves a test accuracy of 0.849, while the SVM-RBF model achieves 0.855. These numbers suggest that non-linear decision boundaries (from SVM-RBF) do help slightly, but a simple linear model is already quite competitive.\nThis is somewhat surprising because Logistic Regression is often treated as a baseline model for classification. The fact that it nearly matches the performance of SVM-RBF indicates that much of the predictive structure in the data can be captured with linear relationships in the encoded feature space. It also suggests that careful preprocessing and regularization can make linear models powerful in high-dimensional, mixed-type datasets.\nWe also checked for signs of overfitting by comparing cross-validation scores to test performance. The test accuracies are in line with the cross-validation estimates, which indicates that the models generalize reasonably well and that our hyperparameter tuning was not overly optimistic. ### Visual checks for interpretability\nFigure 8 shows the strongest positive and negative Logistic Regression coefficients. From these, we find that key features include capital gains, specific occupations, native countries, and relationship status. For example, large positive coefficients for high capital gains or certain professional occupations suggest strong associations with higher income, while negative coefficients for some part-time or lower-wage jobs suggest an association with the &lt;=50K class.\n\n\n\n\n\n\nFigure 8: Top Postive and Negative Logistic Regression Coefficients.\n\n\n\nInterpreting these coefficients in terms of odds ratios, a one-unit increase in a positively weighted feature (or belonging to a positively weighted category) multiplies the odds of having income &gt;50K by a factor greater than 1. Conversely, negative coefficients reduce those odds. This kind of interpretation is not directly available with the SVM-RBF model, which is why Logistic Regression remains attractive despite the small performance gap.\n\nLimitations and Future Work\nThere are several limitations to our approach:\n\nPredictive vs causal: The models capture associations rather than causal effects. We cannot conclude that changing a single feature (e.g., occupation) in isolation would cause income to change.\nFeature set: We only used variables available in the Adult dataset. Important factors such as local labor markets, industry trends, or social networks are not included.\nFairness considerations: Even though we excluded race, the remaining features may still encode structural inequalities. A thorough fairness analysis (e.g., checking group-specific performance metrics) would be an important next step.\n\nFor future work, we should potentially prune irrelevant features to reduce noise and improve robustness. Techniques like recursive feature elimination, regularization path analysis, or dimensionality reduction (PCA or factor analysis) could help identify a more compact feature set (Laxman (2024)). Grouping rare country categories and carefully handling sparse education levels could also make the model steadier and easier to explain.\nOther ideas include:\n\nTrying additional models such as gradient boosting or random forests.\nIncorporating class-weighted loss functions to better capture the minority high-income class.\nEvaluating alternative metrics (precision, recall, F1) specifically for predicting &gt;50K, depending on the application.\n\nOverall, our analysis shows that demographic and employment-related variables can predict income categories with reasonable accuracy, while also highlighting the importance of interpretability, fairness, and careful feature engineering."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "",
    "text": "This Code of Conduct exists to support a respectful, inclusive, and collaborative environment for our team. We wrote it to clarify the values we want to uphold and to give us a simple way to address concerns if they arise. It reflects our commitment to treating each other with fairness and care as we work together on this project. As a team, we pledge to follow this Code and continue improving it as we work and grow together."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#introduction",
    "href": "CODE_OF_CONDUCT.html#introduction",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "",
    "text": "This Code of Conduct exists to support a respectful, inclusive, and collaborative environment for our team. We wrote it to clarify the values we want to uphold and to give us a simple way to address concerns if they arise. It reflects our commitment to treating each other with fairness and care as we work together on this project. As a team, we pledge to follow this Code and continue improving it as we work and grow together."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#reporting-guidelines",
    "href": "CODE_OF_CONDUCT.html#reporting-guidelines",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "Reporting Guidelines",
    "text": "Reporting Guidelines\nIf you experience or witness behaviour that goes against this Code, you have several options for raising the concern. * Speaking directly to the person involved, if you feel safe doing so * Reaching out to another teammate you trust * Contacting the instructor or TA for support * Documenting the situation including dates, messages, or screenshots if it helps bring clarity\nNo retaliation:\nNo one should ever be treated negatively for asking questions or raising concerns in good faith."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behaviour can be brought forward by speaking to a teammate you trust or by contacting the TA or instructor. Any concern raised will be reviewed and handled in a way that is fair, respectful, and appropriate to the situation. We will maintain confidentiality whenever possible and approach each report with care and discretion. If a team member does not follow or uphold this Code in good faith, steps may be taken to address the issue, which may include discussions, adjustments to responsibilities, or escalation to the course team.\nOur aim is always to restore a safe and collaborative working environment."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies to all spaces connected to our project, whether we are collaborating online, meeting in person, or taking part in any activity where we represent the team. This includes GitHub contributions, group chats, shared documents, study sessions, presentations, and any project-related communication on or offline. Team members are expected to uphold these standards whenever their words or actions reflect on the project or its community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-responsibilities",
    "href": "CODE_OF_CONDUCT.html#our-responsibilities",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "Our Responsibilities",
    "text": "Our Responsibilities\nAs teammates working together on this project, we share the responsibility of making our expectations clear and stepping in when behaviour doesn’t align with this Code. We aim to handle concerns fairly and respectfully, and to make decisions that keep our working environment positive and comfortable for everyone.\nWe may also need to review, edit, or ask for changes to contributions whether it’s code, comments, documents, or other project work if they don’t follow the standards in this Code. In some cases, participation may be limited when someone’s actions are disruptive or harmful. These decisions are made thoughtfully and with the goal of protecting the team and the quality of the project."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#updates-and-continuous-improvement",
    "href": "CODE_OF_CONDUCT.html#updates-and-continuous-improvement",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "Updates and Continuous Improvement",
    "text": "Updates and Continuous Improvement\nWe see this Code of Conduct as something that can grow with us. As our project develops, we may notice areas that need more clarity or changes that could better support how we work together. We’re open to adjusting or improving this Code whenever it helps strengthen communication, fairness, or the overall team experience. Everyone is welcome to suggest updates or raise ideas for making it better."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Adult Income Prediction – Team Code of Conduct",
    "section": "Attribution",
    "text": "Attribution\nIn creating this code of conduct we were inspired by the Vox Code of Conduct and the guidelines from Project Include"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Feedback and Contribution",
    "section": "",
    "text": "Feedback and Contribution\nWe welcome any input or feedback on Adult Income Prediction. In particular, we welcome people to propose ideas and submit pull request to our analysis.\nHere are the steps to contribute. The instructions below are provided by Copilot by “Can you please provide me step-by-step instructions how a stranger can get submit pull requests to my public GitHub repo?”\n\nAsk the GitHub repo owner to add you as collaborators.\nClone the repo to your local:\n\ngit clone git@github.com:RNanfuka/AdultIncomePrediction.git\n\nCheck out a new feature name, make changes, and commit.\n\ngit checkout -b feature/feature-name\n\nPush your own branch up.\n\ngit push origin feature/short-descriptor\n\nOpen a pull request on GitHub and add one of us as the reviewer."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "",
    "text": "Here, we tried to find the classification models with the highest accuracy on predicting if an individual’s income is greater than 50K/yr based on census data. Our final classifier has a reasonable performance on the unseen test data. We observed the Logistic Regression validation accuracy of 0.849 and the RBF-SVM test accuracy of 0.855.\nThe prediction model can possibly be further improved by pruning more features that are irrelevant to the prediction, since we are using almost all of the features for fitting the classifiers."
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "",
    "text": "Here, we tried to find the classification models with the highest accuracy on predicting if an individual’s income is greater than 50K/yr based on census data. Our final classifier has a reasonable performance on the unseen test data. We observed the Logistic Regression validation accuracy of 0.849 and the RBF-SVM test accuracy of 0.855.\nThe prediction model can possibly be further improved by pruning more features that are irrelevant to the prediction, since we are using almost all of the features for fitting the classifiers."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "Introduction",
    "text": "Introduction\nA lot of factors impact an individual’s income. We see how wealth remains concentrated as the top 1% held 35% of the total wealth in 2022 (Kuhn and Rı́os-Rull (2025)). More recently, from 2024 to 2025, the U.S. Federal Reserve shows 35% of the family income less than 50K per year (Federal Reserve System (2025)). It is a big topic because it involves each family’s economic well-being.\nThis notebook explores the Adult Income dataset to understand how different demographic and employment characteristics relate to whether a person earns more or less than $50,000 per year. The analysis begins with exploring patterns in the data, identifying any issues, and preparing the dataset for modeling. After cleaning and preprocessing, we build and evaluate predictive models to see how well income levels can be predicted using the available features."
  },
  {
    "objectID": "index.html#methods",
    "href": "index.html#methods",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "Methods",
    "text": "Methods\n\nData\nThe data set used here is from UC Irvine Machine Learning Repository, extracted by Barry Becker from the 1994 Census database (Becker and Kohavi (1996)).\n\n\nAnalysis\nThe algorithms below are considered for predicting whether if an individual’s income was above 50K/year or not: decision tree, k-nearest neighbors (k-nn), support vector machine with RBF kernel (SVM-RBF), logistic regression, gaussian naive bayes. All variables were used to fit the model, with the exception of: - fnlwgt: useless, since each row has a unique value - education-num: due to redundancy with education - race: for ethical reasons.\nData was split with 80% into the test set, and 20% into the train set to increase training time due to the vast amount of data. Imputation, one-hot encoding, and ordinal encoding are all done accordingly with details explained below. For model selection, we first conduct 5-fold cross-validation on all the models with default hyperparameters. Then, we select the top two models (Logistic Regression and SVM-RBF) to conduct a random search of hyperparameters with 5-fold cross-validation using accuracy as the classification metric. Finally, we used the best estimators of each to determine their accuracies on unseen test data.\n\n\nEDA\nLet us first try to look at the number of data points we have for each class.\n\n\n\n\n\n\nFigure 1: Income class distribution. Counts for &lt;=50K vs &gt;50K show the class mix before modeling.\n\n\n\nHere in Figure 1, we clearly see there is class imbalance in the data, with more individuals earning &lt;=50K than &gt;50K. This means that a naive classifier that always predicts the majority class would already achieve non-trivial accuracy. Therefore, we must compare our models not just to a 50–50 baseline but also to this majority-class baseline. In future work, we could explore class-weighted loss functions or threshold tuning to better capture the minority high-income group.\n\nCorrelations and Redundancy\n\n\n\n\n\n\nFigure 2: Features Correlations Heatmap.\n\n\n\nIn Figure 2, we see that there are no extremely strong correlations between any pair of features, suggesting that severe multicollinearity is unlikely. Some moderate associations exist (e.g., between age and education, or hours worked and income-related variables), but they are not high enough to destabilize models like Logistic Regression. This supports our decision to keep most features, while still considering more advanced dimensionality reduction or feature selection later.\nTaken together, these first checks show a moderate class imbalance and largely mild correlations, so we plan to watch class weighting while keeping most features intact for modeling.\n\n\nKey Distributions\n\n\n\n\n\n\nFigure 3: Age distribution (smoothed density). The density view confirms the central mass in mid-career ages.\n\n\n\nFigure Figure 3 shows a skew toward mid-career ages, suggesting that experience- and tenure-related features may be informative. We also expect interactions with hours worked and education, since older individuals with higher education might have different income trajectories than younger individuals working similar hours.\nThe bulk of observations sit in the prime working ages, so discriminating power may come more from labor variables (hours, occupation) and capital gains than from age alone.\n\n\n\n\n\n\nFigure 4: Education levels. Higher counts appear in high-school/some-college bins; advanced degrees are rarer.\n\n\n\nFigure 4 highlights that most of the population clusters around mid-tier education levels such as high school and some college. Advanced degrees (e.g., Masters, Doctorate) are relatively rare, which means that their corresponding one-hot encoded levels have few observations. Regularization or grouping of similar education categories can prevent the model from overreacting to these small bins while still capturing the broad effect of education on income. grouping can prevent the model from overreacting to those small bins while still capturing the broad education effect.\n\n\n\n\n\n\nFigure 5: Race distribution. Most records fall in the majority category, with smaller minority groups.\n\n\n\nFigure 5 shows class imbalance across race groups, which reinforces the need for careful interpretation of fairness and representation. Even though we chose to exclude race from our predictive models for ethical reasons, this imbalance is important context for understanding the demographic makeup of the dataset and the societal factors behind income disparities.\nThis imbalance means any downstream interpretation should consider fairness; we may explore reweighting or sensitivity checks in future work to ensure predictions are not driven by majority representation alone.\n\n\n\n\n\n\nFigure 6: Marital status distribution. Married categories dominate, followed by never-married.\n\n\n\nFigure 6 suggests marital status may proxy for household stability or earning patterns; for instance, married individuals might have different labor participation or income levels than those who are never married. We expect interactions with occupation, hours worked, and possibly age.\nMarital status can also interact with dependents and life stage; inspecting combined effects will show whether it truly adds signal or just tracks broader demographic patterns.\n\n\n\n\n\n\nFigure 7: Native country counts. The vast majority are from the United States; other countries are sparse.\n\n\n\nFigure 7 shows heavy sparsity outside the United States, so grouping rare countries into broader regions (e.g., “Other”) could stabilize estimates and reduce noise in the model. Without grouping, many country-level dummy variables would be based on very few observations.\nOverall, the categorical sparsity (education extremes, non-U.S. countries) and demographic skews (race, marital status) argue for careful encoding and potential grouping, while the moderate class imbalance suggests testing class weights during model training.\n\n\n\nModel comparison and interpretation\nFrom Table 1, we can see that RBF-SVM is slightly more accurate than the other models. Logistic Regression is close in accuracy, and its interpretability is better due to its use of linear coefficients that can be mapped to odds ratios. Decision trees and k-NN trail behind in accuracy under the chosen preprocessing and hyperparameter defaults, and Gaussian Naive Bayes performs the worst, likely because its independence assumptions do not hold well for this dataset.\n\n\n\n\nTable 1: Cross validation summary for different models.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel\ntrain_accuracy_mean\ntrain_accuracy_std\ntest_accuracy_mean\ntest_accuracy_std\nfit_time_mean\nscore_time_mean\n\n\n\n\nSVM-RBF\n0.866247\n0.00147473\n0.855037\n0.00667547\n0.586047\n0.309393\n\n\nLogisticRegression\n0.851454\n0.00191879\n0.849304\n0.0078078\n0.0400904\n0.00131488\n\n\nKNN\n0.88232\n0.00180596\n0.834049\n0.00638451\n0.00424371\n0.0638126\n\n\nDecisionTree\n0.985437\n0.000514588\n0.814189\n0.0045412\n0.0195274\n0.00144496\n\n\nDummy-most_frequent\n0.760749\n5.3867e-05\n0.760749\n0.000215433\n0.00200963\n0.000862169\n\n\nGaussianNB\n0.309787\n0.00417648\n0.308148\n0.0104979\n0.00577421\n0.00150285\n\n\n\n\n\n\n\n\nThere is also a computational trade-off: SVM-RBF is more expensive to train and tune than Logistic Regression, especially on large datasets with many one-hot encoded features. Thus, the choice between these models depends not only on accuracy but also on interpretability and computational constraints. In many applied settings, Logistic Regression may be a more practical default."
  },
  {
    "objectID": "index.html#results-and-discussion",
    "href": "index.html#results-and-discussion",
    "title": "Predicting Adult Income via Demographics Data",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nFrom the analyses above, we discovered that Logistic Regression and SVM-RBF are the best classification models for predicting income among the algorithms we tried. The Logistic Regression model achieves a test accuracy of 0.849, while the SVM-RBF model achieves 0.855. These numbers suggest that non-linear decision boundaries (from SVM-RBF) do help slightly, but a simple linear model is already quite competitive.\nThis is somewhat surprising because Logistic Regression is often treated as a baseline model for classification. The fact that it nearly matches the performance of SVM-RBF indicates that much of the predictive structure in the data can be captured with linear relationships in the encoded feature space. It also suggests that careful preprocessing and regularization can make linear models powerful in high-dimensional, mixed-type datasets.\nWe also checked for signs of overfitting by comparing cross-validation scores to test performance. The test accuracies are in line with the cross-validation estimates, which indicates that the models generalize reasonably well and that our hyperparameter tuning was not overly optimistic. ### Visual checks for interpretability\nFigure 8 shows the strongest positive and negative Logistic Regression coefficients. From these, we find that key features include capital gains, specific occupations, native countries, and relationship status. For example, large positive coefficients for high capital gains or certain professional occupations suggest strong associations with higher income, while negative coefficients for some part-time or lower-wage jobs suggest an association with the &lt;=50K class.\n\n\n\n\n\n\nFigure 8: Top Postive and Negative Logistic Regression Coefficients.\n\n\n\nInterpreting these coefficients in terms of odds ratios, a one-unit increase in a positively weighted feature (or belonging to a positively weighted category) multiplies the odds of having income &gt;50K by a factor greater than 1. Conversely, negative coefficients reduce those odds. This kind of interpretation is not directly available with the SVM-RBF model, which is why Logistic Regression remains attractive despite the small performance gap.\n\nLimitations and Future Work\nThere are several limitations to our approach:\n\nPredictive vs causal: The models capture associations rather than causal effects. We cannot conclude that changing a single feature (e.g., occupation) in isolation would cause income to change.\nFeature set: We only used variables available in the Adult dataset. Important factors such as local labor markets, industry trends, or social networks are not included.\nFairness considerations: Even though we excluded race, the remaining features may still encode structural inequalities. A thorough fairness analysis (e.g., checking group-specific performance metrics) would be an important next step.\n\nFor future work, we should explore multiple options, including conducting a more extensive hyperparameter searching on logistic regression or SVM-RBF and using techniques like recursive feature elimination, regularization path analysis, or dimensionality reduction methods to reduce possible noise in features (Laxman (2024)). Grouping rare country categories and carefully handling sparse education levels could also make the model steadier and easier to explain.\nOther ideas include:\n\nTrying additional models such as gradient boosting or random forests.\nIncorporating class-weighted loss functions to better capture the minority high-income class.\nEvaluating alternative metrics (precision, recall, F1) specifically for predicting &gt;50K, depending on the application.\n\nOverall, our analysis shows that demographic and employment-related variables can predict income categories with reasonable accuracy, while also highlighting the importance of interpretability, fairness, and careful feature engineering."
  }
]